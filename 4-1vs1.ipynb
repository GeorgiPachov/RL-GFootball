{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "610f9764-5d1e-4f80-8902-b383aa67c0db",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d1eb07-904f-4216-bab3-efeea53da3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "! brew install git python3 cmake sdl2 sdl2_image sdl2_ttf sdl2_gfx boost boost-python3\n",
    "! python3 -m pip install --upgrade pip setuptools psutil wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1339f7-ad25-42c0-8321-156fa439cc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install gfootball "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec1b2ba-fe09-4890-b460-fe10573ca7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install setuptools==65.5.0\n",
    "! git clone https://github.com/google-research/football.git\n",
    "! cd football && pip install . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cb6696-a2ba-4c05-b837-03542bf537ce",
   "metadata": {},
   "source": [
    "### Test game play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9949d48d-0d45-4b59-bf29-dd1da18b82b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objc[81026]: Class SDLApplication is implemented in both /opt/homebrew/Cellar/sdl2/2.26.3/lib/libSDL2-2.0.0.dylib (0x106368800) and /Users/georgipachov/opt/miniconda3/envs/rl/lib/python3.10/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x1321287e8). One of the two will be used. Which one is undefined.\n",
      "objc[81026]: Class SDLAppDelegate is implemented in both /opt/homebrew/Cellar/sdl2/2.26.3/lib/libSDL2-2.0.0.dylib (0x106368850) and /Users/georgipachov/opt/miniconda3/envs/rl/lib/python3.10/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x132128838). One of the two will be used. Which one is undefined.\n",
      "objc[81026]: Class SDLTranslatorResponder is implemented in both /opt/homebrew/Cellar/sdl2/2.26.3/lib/libSDL2-2.0.0.dylib (0x1063688c8) and /Users/georgipachov/opt/miniconda3/envs/rl/lib/python3.10/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x1321288b0). One of the two will be used. Which one is undefined.\n",
      "objc[81026]: Class SDLMessageBoxPresenter is implemented in both /opt/homebrew/Cellar/sdl2/2.26.3/lib/libSDL2-2.0.0.dylib (0x1063688f0) and /Users/georgipachov/opt/miniconda3/envs/rl/lib/python3.10/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x1321288d8). One of the two will be used. Which one is undefined.\n",
      "objc[81026]: Class SDL_cocoametalview is implemented in both /opt/homebrew/Cellar/sdl2/2.26.3/lib/libSDL2-2.0.0.dylib (0x106368940) and /Users/georgipachov/opt/miniconda3/envs/rl/lib/python3.10/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x132128928). One of the two will be used. Which one is undefined.\n",
      "objc[81026]: Class SDLOpenGLContext is implemented in both /opt/homebrew/Cellar/sdl2/2.26.3/lib/libSDL2-2.0.0.dylib (0x106368990) and /Users/georgipachov/opt/miniconda3/envs/rl/lib/python3.10/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x132128978). One of the two will be used. Which one is undefined.\n",
      "objc[81026]: Class SDLWindow is implemented in both /opt/homebrew/Cellar/sdl2/2.26.3/lib/libSDL2-2.0.0.dylib (0x106368b20) and /Users/georgipachov/opt/miniconda3/envs/rl/lib/python3.10/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x1321289c8). One of the two will be used. Which one is undefined.\n",
      "objc[81026]: Class Cocoa_WindowListener is implemented in both /opt/homebrew/Cellar/sdl2/2.26.3/lib/libSDL2-2.0.0.dylib (0x106368b48) and /Users/georgipachov/opt/miniconda3/envs/rl/lib/python3.10/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x1321289f0). One of the two will be used. Which one is undefined.\n",
      "objc[81026]: Class SDLView is implemented in both /opt/homebrew/Cellar/sdl2/2.26.3/lib/libSDL2-2.0.0.dylib (0x106368bc0) and /Users/georgipachov/opt/miniconda3/envs/rl/lib/python3.10/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x132128a68). One of the two will be used. Which one is undefined.\n",
      "objc[81026]: Class METAL_RenderData is implemented in both /opt/homebrew/Cellar/sdl2/2.26.3/lib/libSDL2-2.0.0.dylib (0x106368c38) and /Users/georgipachov/opt/miniconda3/envs/rl/lib/python3.10/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x132128ab8). One of the two will be used. Which one is undefined.\n",
      "objc[81026]: Class METAL_TextureData is implemented in both /opt/homebrew/Cellar/sdl2/2.26.3/lib/libSDL2-2.0.0.dylib (0x106368c88) and /Users/georgipachov/opt/miniconda3/envs/rl/lib/python3.10/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x132128b08). One of the two will be used. Which one is undefined.\n",
      "objc[81026]: Class SDL_RumbleMotor is implemented in both /opt/homebrew/Cellar/sdl2/2.26.3/lib/libSDL2-2.0.0.dylib (0x106368cb0) and /Users/georgipachov/opt/miniconda3/envs/rl/lib/python3.10/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x132128b58). One of the two will be used. Which one is undefined.\n",
      "objc[81026]: Class SDL_RumbleContext is implemented in both /opt/homebrew/Cellar/sdl2/2.26.3/lib/libSDL2-2.0.0.dylib (0x106368d00) and /Users/georgipachov/opt/miniconda3/envs/rl/lib/python3.10/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x132128ba8). One of the two will be used. Which one is undefined.\n",
      "pygame 2.2.0 (SDL 2.0.22, Python 3.10.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "UNSUPPORTED (log once): POSSIBLE ISSUE: unit 1 GLD_TEXTURE_INDEX_2D is unloadable and bound to sampler type (Float) - using zero texture because texture unloadable\n",
      "^C\n",
      "W0307 11:21:45.448897 4385031552 play_game.py:65] Game stopped, writing dump...\n",
      "I0307 11:21:45.453339 4385031552 observation_processor.py:361] Dump written to /var/folders/4x/vb5tl80s45v2f_k7_zb004bc0000gn/T/dumps/shutdown_20230307-112145449051.dump\n",
      "I0307 11:21:45.572648 4385031552 observation_processor.py:361] Dump written to /var/folders/4x/vb5tl80s45v2f_k7_zb004bc0000gn/T/dumps/episode_done_20230307-112130066776.dump\n"
     ]
    }
   ],
   "source": [
    "! python -m gfootball.play_game --action_set=full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e868fc7-3c4f-4e4c-8013-526abcd35326",
   "metadata": {},
   "source": [
    "### Learning environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71616c53-f3a5-4dfe-9505-04ff58a24c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "import gym\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import namedtuple\n",
    "import gfootball\n",
    "import gfootball.env as football_env\n",
    "from gfootball.env.wrappers import Simple115StateWrapper\n",
    "import collections\n",
    "\n",
    "SavedAction = namedtuple('SavedAction', ['log_prob', 'value'])\n",
    "\n",
    "class ShapingRewardWrapper(gym.Wrapper):\n",
    "        def __init__(self, env):\n",
    "            super().__init__(env)\n",
    "            self.observation_space = collections.namedtuple('ObservationSpace', 'shape')\n",
    "            self.observation_space.shape=(115,)\n",
    "            self._env = env\n",
    "\n",
    "            self._bo = 0.02\n",
    "            \n",
    "            # attack vs defense coefficients\n",
    "            self._dist_mg = 0.01\n",
    "            self._dist_og = 0.01\n",
    "            \n",
    "            self._opdist = 0.1\n",
    "            self._goal_bonus = 100\n",
    "\n",
    "        \n",
    "        def step(self, action):\n",
    "            obs, reward, done, info = self._env.step(action)\n",
    "            reward *= self._goal_bonus\n",
    "            obs = obs[0]\n",
    "\n",
    "            if obs['ball_owned_team'] == 0:\n",
    "                reward += self._bo\n",
    "            elif obs['ball_owned_team'] == 1:\n",
    "                reward -= self._bo\n",
    "\n",
    "            bx, by, bz = obs['ball']\n",
    "            mgx, mgy = -1, 0\n",
    "            ogx, ogy = 1, 0\n",
    "            \n",
    "            dist_from_my_goal = (np.sqrt((bx-mgx)**2 + (by-mgy)**2))\n",
    "            dist_from_opponent_goal = (np.sqrt((bx-ogx)**2 + (by-ogy)**2))\n",
    "            \n",
    "            reward += self._dist_mg * dist_from_my_goal\n",
    "            reward += self._dist_og * dist_from_opponent_goal\n",
    "\n",
    "            # distance of controlling player from ball \n",
    "            mx, my = obs['left_team'][obs['active']]\n",
    "            if obs['ball_owned_team'] != 0:\n",
    "                reward -= self._opdist * (np.sqrt((bx-mx)**2 + (by-my)**2))\n",
    "                \n",
    "            return obs, reward, done, info\n",
    "\n",
    "        \n",
    "def obs_transform(obs):\n",
    "    return Simple115StateWrapper.convert_observation(obs, True)\n",
    "\n",
    "\n",
    "def create_env(render=False, \n",
    "               env_name='academy_empty_goal', \n",
    "               wrapper_init=None,\n",
    "               record=True,\n",
    "               **params):\n",
    "    if env_name == 'cart_pole':\n",
    "        env = gym.make('CartPole-v0')\n",
    "    else:\n",
    "        env_names = ['1_vs_1_easy', '5_vs_5', 'academy_run_to_score', 'academy_empty_goal_close', 'academy_empty_goal']\n",
    "        os.environ['MESA_GL_VERSION_OVERRIDE'] = '3.3'\n",
    "        env = football_env.create_environment(env_name=env_name, \n",
    "                                              stacked=False, \n",
    "                                              representation='raw',\n",
    "                                              rewards='scoring,checkpoints',\n",
    "                                              logdir='replays', \n",
    "                                              write_goal_dumps=record, \n",
    "                                              write_full_episode_dumps=record, \n",
    "                                              write_video=record,\n",
    "                                              render=render)\n",
    "        if wrapper_init is not None:\n",
    "            return wrapper_init.__call__(env)\n",
    "        else:\n",
    "            return env\n",
    "\n",
    "\n",
    "class Policy(nn.Module):\n",
    "    \"\"\"\n",
    "    implements both actor and critic in one model\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.affine1 = nn.Linear(115, 128)\n",
    "\n",
    "        # actor's layer\n",
    "        self.action_head = nn.Linear(128, 19)\n",
    "\n",
    "        # critic's layer\n",
    "        self.value_head = nn.Linear(128, 1)\n",
    "\n",
    "        # action & reward buffer\n",
    "        self.saved_actions = []\n",
    "        self.rewards = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        forward of both actor and critic\n",
    "        \"\"\"\n",
    "        x = F.relu(self.affine1(x))\n",
    "\n",
    "        # actor: choses action to take from state s_t \n",
    "        # by returning probability of each action\n",
    "        action_prob = F.softmax(self.action_head(x), dim=-1)\n",
    "\n",
    "        # critic: evaluates being in the state s_t\n",
    "        state_values = self.value_head(x)\n",
    "\n",
    "        # return values for both actor and critic as a tuple of 2 values:\n",
    "        # 1. a list with the probability of each action over the action space\n",
    "        # 2. the value from state s_t \n",
    "        return action_prob, state_values\n",
    "\n",
    "\n",
    "def select_action(model, state, in_training):\n",
    "    state = torch.from_numpy(state).float()\n",
    "    probs, state_value = model(state)\n",
    "\n",
    "    # create a categorical distribution over the list of probabilities of actions\n",
    "    m = Categorical(probs)\n",
    "\n",
    "    if in_training:\n",
    "        # and sample an action using the distribution\n",
    "        action = m.sample()\n",
    "    else:\n",
    "        action = torch.argmax(probs)\n",
    "        \n",
    "    # save to action buffer\n",
    "    model.saved_actions.append(SavedAction(m.log_prob(action), state_value))\n",
    "\n",
    "    return action.item()\n",
    "\n",
    "\n",
    "def finish_episode(model, optimizer, gamma, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Training code. Calculates actor and critic loss and performs backprop.\n",
    "    \"\"\"\n",
    "    R = 0\n",
    "    saved_actions = model.saved_actions\n",
    "    policy_losses = [] # list to save actor (policy) loss\n",
    "    value_losses = [] # list to save critic (value) loss\n",
    "    returns = [] # list to save the true values\n",
    "\n",
    "    # calculate the true value using rewards returned from the environment\n",
    "    for r in model.rewards[::-1]:\n",
    "        # calculate the discounted value\n",
    "        R = r + gamma * R\n",
    "        returns.insert(0, R)\n",
    "\n",
    "    returns = torch.tensor(returns)\n",
    "    returns = (returns - returns.mean()) / (returns.std() + eps)\n",
    "\n",
    "    for (log_prob, value), R in zip(saved_actions, returns):\n",
    "        advantage = R - value.item()\n",
    "\n",
    "        # calculate actor (policy) loss \n",
    "        policy_losses.append(-log_prob * advantage)\n",
    "\n",
    "        # calculate critic (value) loss using L1 smooth loss\n",
    "        value_losses.append(F.smooth_l1_loss(value, torch.tensor([R])))\n",
    "\n",
    "    # reset gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # sum up all the values of policy_losses and value_losses\n",
    "    loss = torch.stack(policy_losses).sum() + torch.stack(value_losses).sum()\n",
    "\n",
    "    # perform backprop\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # reset rewards and action buffer\n",
    "    del model.rewards[:]\n",
    "    del model.saved_actions[:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f1b930-66e4-46c5-95b6-3b935df05f38",
   "metadata": {},
   "source": [
    "### Learning objective: Run to score with keeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fde2304-0602-49e5-83c1-519412e1e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceFromOpponentGoalReward(gym.Wrapper):\n",
    "        def __init__(self, env):\n",
    "            super().__init__(env)\n",
    "            self._env = env\n",
    "        \n",
    "        def step(self, action):\n",
    "            obs, reward, done, info = self._env.step(action)\n",
    "            reward = 0\n",
    "            \n",
    "            obs = obs[0]\n",
    "\n",
    "            bx, by, bz = obs['ball']\n",
    "            ogx, ogy = -1, 0\n",
    "            \n",
    "            dist_from_opponent_goal = (np.sqrt((bx-ogx)**2 + (by-ogy)**2))\n",
    "            reward -= dist_from_opponent_goal\n",
    "            \n",
    "            return obs, reward, done, info\n",
    "        \n",
    "class DistanceFromOpponentGoalRewardFixed(gym.Wrapper):\n",
    "        def __init__(self, env):\n",
    "            super().__init__(env)\n",
    "            self._env = env\n",
    "        \n",
    "        def step(self, action):\n",
    "            obs, reward, done, info = self._env.step(action)\n",
    "            reward = 0\n",
    "            \n",
    "            obs = obs[0]\n",
    "            goals_left_team = obs['score'][0]\n",
    "            reward += goals_left_team * 10000\n",
    "            lost_ball = obs['ball_owned_team'] == 1\n",
    "            if lost_ball:\n",
    "                reward -= 10000\n",
    "        \n",
    "            bx, by, bz = obs['ball']\n",
    "            ogx, ogy = 1, 0\n",
    "            \n",
    "            dist_from_opponent_goal = (np.sqrt((bx-ogx)**2 + (by-ogy)**2))\n",
    "            reward -= dist_from_opponent_goal\n",
    "\n",
    "            \n",
    "            return obs, reward, done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2f3ff58-c309-4dc0-b274-8de57746a440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_agent(exp_name='exp1',\n",
    "              model=None,\n",
    "              train=True,\n",
    "              render=False,\n",
    "              record=False, \n",
    "              num_episodes=2000,\n",
    "              num_steps=500,\n",
    "              task='academy_empty_goal_close',\n",
    "              wrapper_init=DistanceFromOpponentGoalReward,\n",
    "              policy_fn=Policy,\n",
    "              solved_threshold=-25,\n",
    "              log_every=50,\n",
    "              learning_rate=1e-2,\n",
    "              gamma=0.99,\n",
    "              last_n=5,\n",
    "              seed=0,\n",
    "              checkpoint=True,\n",
    "              checkpoint_dir='checkpoints'\n",
    "             ):\n",
    "    # set seed first\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    if not train:\n",
    "        model.eval()\n",
    "                \n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.mkdir(checkpoint_dir)\n",
    "    \n",
    "    try: \n",
    "        max_reward = -1_000_000\n",
    "        running_reward = 0\n",
    "        episode_rewards = []\n",
    "        env = create_env(render=render, \n",
    "                         env_name=task,\n",
    "                         record=record,\n",
    "                         wrapper_init=wrapper_init)\n",
    "        if model is None:\n",
    "            model = policy_fn()\n",
    "            \n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        # eps = np.finfo(np.float32).eps.item()\n",
    "        eps = 1e-8\n",
    "\n",
    "        for i_episode in range(num_episodes):\n",
    "            # reset environment and episode reward\n",
    "            state = env.reset()\n",
    "            state = obs_transform(state)\n",
    "            ep_reward = 0\n",
    "\n",
    "            # for each episode, only run 9999 steps so that we don't \n",
    "            # infinite loop while learning\n",
    "            for t in range(1, num_steps):\n",
    "\n",
    "                # select action from policy\n",
    "                action = select_action(model, state, train)\n",
    "\n",
    "                # take the action\n",
    "                state, reward, done, _ = env.step(action)\n",
    "                state = obs_transform([state])\n",
    "\n",
    "                model.rewards.append(reward)\n",
    "                ep_reward += reward\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "                    \n",
    "            # log results\n",
    "            episode_rewards.append(ep_reward)\n",
    "            \n",
    "            # update cumulative reward\n",
    "            running_reward = np.mean(episode_rewards[-last_n:])\n",
    "            \n",
    "            if i_episode % log_every == 0:\n",
    "                print(f'Episode: {i_episode}\\tLast reward: {ep_reward:.2f} \\t Last {last_n} episodes average reward: {running_reward}')\n",
    "\n",
    "            if train:\n",
    "                # save checkpoint\n",
    "                if checkpoint:\n",
    "                    if running_reward > max_reward:\n",
    "                        torch.save(model, f'{checkpoint_dir}/{running_reward}_{task}_{exp_name}_checkpoint_{i_episode}.h5')\n",
    "                        max_reward = running_reward\n",
    "\n",
    "                if i_episode > last_n and running_reward > solved_threshold:\n",
    "                    torch.save(model, f'{task}_{exp_name}.h5')\n",
    "                    print('Solved!')\n",
    "                    return model, episode_rewards\n",
    "                \n",
    "                else:\n",
    "                    # perform backprop\n",
    "                    finish_episode(model, optimizer, gamma)\n",
    "                \n",
    "        return model, episode_rewards\n",
    "    finally: \n",
    "        env.close()\n",
    "        \n",
    "def load_best_agent(checkpoints_dir='checkpoints'):\n",
    "    # Load best agent\n",
    "    checkpoints = os.listdir(checkpoints_dir)\n",
    "    all_checkpoints = {int(x[:x.index('.')]):x for x in checkpoints}\n",
    "    max_reward = max(all_checkpoints.keys())\n",
    "    best = all_checkpoints[max_reward]\n",
    "    print('Loading checkpoint: ', best)\n",
    "    model_loaded = torch.load(os.path.join(checkpoints_dir, best))\n",
    "    return model_loaded\n",
    "\n",
    "def load_agent(name, checkpoints_dir='checkpoints'):\n",
    "    # Load manually\n",
    "    print('Loading checkpoint: ', name)\n",
    "    model_loaded = torch.load(os.path.join(checkpoints_dir, name))\n",
    "    return model_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc93393a-c714-4f03-a639-703650d7bb09",
   "metadata": {},
   "source": [
    "### 1 vs 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d4ae9f9-c586-4ac7-ab06-1927be76b1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0\tLast reward: -49.00 \t Last 100 episodes average reward: -49.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/vb5tl80s45v2f_k7_zb004bc0000gn/T/ipykernel_99455/2395396733.py:174: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  value_losses.append(F.smooth_l1_loss(value, torch.tensor([R])))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 100\tLast reward: -49.00 \t Last 100 episodes average reward: -49.0\n",
      "Episode: 200\tLast reward: -49.00 \t Last 100 episodes average reward: -49.0\n",
      "Episode: 300\tLast reward: -49.00 \t Last 100 episodes average reward: -49.0\n",
      "Episode: 400\tLast reward: -49.00 \t Last 100 episodes average reward: -49.0\n",
      "Episode: 500\tLast reward: -49.00 \t Last 100 episodes average reward: -49.0\n",
      "Episode: 600\tLast reward: -49.00 \t Last 100 episodes average reward: -49.0\n",
      "Episode: 700\tLast reward: -49.00 \t Last 100 episodes average reward: -49.0\n",
      "Episode: 800\tLast reward: -49.00 \t Last 100 episodes average reward: -49.0\n",
      "Episode: 900\tLast reward: -49.00 \t Last 100 episodes average reward: -49.0\n"
     ]
    }
   ],
   "source": [
    "model, episode_rewards = run_agent(train=True,\n",
    "                                   render=False,\n",
    "                                   record=False,\n",
    "                                   log_every=100,\n",
    "                                   num_steps=50,\n",
    "                                   num_episodes=1000,\n",
    "                                   seed=42,\n",
    "                                   last_n=100,\n",
    "                                   solved_threshold=-35, \n",
    "                                   task='1_vs_1_easy', \n",
    "                                   learning_rate=5e-1,\n",
    "                                   wrapper_init=DistanceFromOpponentGoalRewardFixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "835de4f1-dea3-4967-a4db-45ad18db15a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: title={'center': 'Mean reward for last 20 episodes'}, xlabel='Еpisode', ylabel='Reward'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(episode_rewards).rolling(5).mean().plot(xlabel='Еpisode', ylabel='Reward', title='Mean reward for last 20 episodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44691286-017d-454e-b195-18fee023f548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UNSUPPORTED (log once): POSSIBLE ISSUE: unit 1 GLD_TEXTURE_INDEX_2D is unloadable and bound to sampler type (Float) - using zero texture because texture unloadable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0\tLast reward: -1100576.59 \t Last 5 episodes average reward: -1100576.5864640274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Policy(\n",
       "   (affine1): Linear(in_features=115, out_features=128, bias=True)\n",
       "   (action_head): Linear(in_features=128, out_features=19, bias=True)\n",
       "   (value_head): Linear(in_features=128, out_features=1, bias=True)\n",
       " ),\n",
       " [-1100576.5864640274,\n",
       "  -490544.0772367845,\n",
       "  3199562.2420807914,\n",
       "  -1200570.6406743035,\n",
       "  -60659.689148209014,\n",
       "  1889458.7273285643,\n",
       "  2879613.249817989,\n",
       "  -410636.739884214,\n",
       "  -660618.2235382118,\n",
       "  -1200543.5959589153])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_agent(model=model, \n",
    "          train=False, \n",
    "          render=True, \n",
    "          record=True,\n",
    "          seed=42, \n",
    "          num_episodes=10,\n",
    "          task='1_vs_1_easy', \n",
    "          wrapper_init=DistanceFromOpponentGoalRewardFixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a36d150e-6683-4294-a00f-dbe0a6e2edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/google-research/football/blob/master/gfootball/doc/observation.md#raw-observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39e32f8-f88e-4d97-922c-44359b8805fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# academy_empty_goal_close\n",
    "# academy_empty_goal\n",
    "# academy_run_to_score\n",
    "# academy_run_to_score_with_keeper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
